# 論文情報・リンク
論文リンク： https://ai.stanford.edu/~ronnyk/2009controlledExperimentsOnTheWebSurvey.pdf
公開日時： Published online: 30 July 2008; Journal issue: February 2009 ￼ ￼
実装コード： 内部実装プラットフォーム「ExP」（Microsoft内部・非公開）を紹介 ￼
Publication : Data Mining and Knowledge Discovery, Vol. 18, No. 1, pp. 140–181 (2009) ￼

# Abstract

制御実験（ランダム化実験、A/Bテストおよびその拡張、スプリットテスト、Control/Treatmentテスト、多変量テスト（MVT）、並行フライトとも呼ばれる）は、変更とユーザーの観察可能な行動への因果関係を確立するための、最も理にかなった科学的デザインを体現しています。本稿では、エンドユーザーの反応を活かして機能開発を導くオンライン実験の実践的ガイドを提供します。私たちの経験から、開発チームが「Highest Paid Person’s Opinion（HiPPO）」ではなく顧客の声に耳を傾けることで、大きな学びと投資収益率（ROI）が得られることが明らかになっています。

本稿では、驚くべき結果をもたらしたいくつかの制御実験事例を紹介するとともに、実験を実行する上で必要な重要要素と、その技術的・組織的な制約について論じます。特に、統計的検出力、サンプルサイズ、分散削減のための手法といった、実験設計における要所に焦点を当てています。

また、実験システムの一般的なアーキテクチャを説明し、それぞれの利点・欠点を分析します。さらに、実際には単純とは言えないランダム化およびハッシュ化技術についても評価を行います。

制御実験は通常、大量のデータを生み出しますが、これをデータマイニング技術で分析することで、結果に影響を与える要因を深く理解し、新たな仮説を生み出し、改善の好循環を生み出せます。明確な評価基準のもとで制御実験を取り入れる組織は、自動最適化やリアルタイム分析を通じてシステムを継続的に進化させることが可能です。

私たちは複数のシステムや組織での豊富な実践経験に基づき、信頼性の高い制御実験を実施するための重要な教訓を本稿で共有します。


# 1 Introduction
「千の専門家の意見に勝るは、一つの正確な測定である」
― アドミラル・グレース・ホッパー
1700年代、ある英国海軍の船長は、地中海方面の艦隊に配属された水兵が壊血病（スコルブ）の症状をほとんど示さないことに気づきました。彼らの配給食には柑橘類が含まれていたのです。そこで船長は乗組員を二つのグループに分け、一方（Treatment 群）にはライムを与え、もう一方（Control 群）には従来通りの食事を続けさせる実験を行いました。Treatment 群では不満の声も上がりましたが、実験は成功し、ライムの摂取が壊血病の予防に効果的であることが示されました。船長自身は壊血病がビタミンC欠乏によるものであることや、ライムに豊富にビタミンCが含まれていることを理解していませんでしたが、この介入は確実に功を奏しました。やがて英国水兵には定期的に柑橘類を摂取することが義務づけられ、その習慣が「ライミーズ（limeys）」という愛称を生むに至りました（Rossi et al. 2003; Marks 2000）。

それから約300年後、Amazon のグレッグ・リンデンは、ショッピングカートに入れた商品の履歴に応じてパーソナライズされた推薦を表示するプロトタイプを開発しました（Linden 2006a, b）。商品を一つ追加すると推薦が現れ、別の商品を追加すると別の推薦が表示される仕組みです。このアイデアは一見有望でしたが、あるマーケティング上級副社長は「チェックアウトの妨げになる」と断固反対し、リンデンは「これ以上手をつけるな」と命じられました。しかし、彼はそれでも制御実験を実施し、その機能は圧倒的な差で勝利を収め、「未導入のままでいることが Amazon にかなりの損失を与えている」ことが明らかになりました。急遽ショッピングカート推薦機能が本番導入され、その後、多くのサイトが同様の仕組みを採用しています。

本論文の著者たちは、Amazon、Microsoft、DuPont、NASA などで数多くの実験に携わってきました。特に Amazon では「直感よりデータを重視する」という文化と、実験を容易に行えるシステムが整備されており、迅速かつ効果的なイノベーションを可能にしています。Microsoft においても複数の制御実験システムが運用されており、本論文ではそれぞれのアーキテクチャの利点と欠点を解説します。本稿の一貫したテーマは、制御実験が優れた投資収益率（ROI）を生み出し、適切なインフラストラクチャを構築することでイノベーションのスピードを加速できるという点です。Stefan Thomke の著書『Experimentation Matters』（Thomke 2003）のタイトルは、その趣旨を端的に示しています。

Webは、制御実験（ランダム化実験：単因子設計または因子設計）、A/Bテスト（およびその一般化）、スプリットテスト、Control/Treatmentテスト、並行フライトといった手法を用いて、アイデアを迅速に評価するための前例のない機会を提供します。これらの実験の最もシンプルな形では、実際のユーザーをランダムに二つのバリアントのいずれかに割り当てます。(i) Control（通常は「既存」バージョン）、(ii) Treatment（評価対象となる新バージョン）です。実行時パフォーマンスから、暗黙的・明示的ユーザー行動、アンケートデータまで、多様な指標を収集し、統計検定を適用して、両バリアント間に有意差があるかどうかを判断します。これにより、「バージョン間に差はない」という帰無仮説を維持するか棄却するかを決定できます。さらに、OLAPなどの手動分析や機械学習・データマイニング技術によってユーザーセグメントを掘り下げることで、どのサブポピュレーションにおいて差が顕著かを明らかにし、アイデア理解を深め、次のステップへ進む助けとします。

制御実験は、アイデアを確実に評価するための方法論を提供します。事後分析や中断時系列分析（準実験法）などとは異なり、本手法は因果関係を検証するための実験デザインです（Keppel et al. 1992, pp. 5–6）。多くの組織には多彩なアイデアがありますが、そのROI（投資収益率）が不明瞭だったり、評価コストが高かったりします。しかし次節で示すように、わずかな変更が大きな違いを生むことがあり、その結果はしばしば予測を超えます。本番環境での実験は、アイデアの価値を見極めるうえで強力な指針を与えてくれます。

本稿の貢献は以下のとおりです。
- 第3節では、Web環境における制御実験の概要をレビューし、統計的検出力やサンプルサイズといった、初学者向け解説ではしばしば省略されがちな重要項目を含む豊富な文献を紹介します。さらに実務で有効だった分散削減手法、実践上の拡張・制約も論じ、実務者が陥りやすい落とし穴を回避できるようにします。
- 第4節では、オンライン環境における多変量テスト（MVT）の代替策を複数提示します。ソフトウェア領域では、従来型MVTよりも並行した一因子テストのほうが適している場合がある理由を論じます。
- 第5節では、著者が関与してきた複数の実験システムを統合する汎用アーキテクチャを示し、その長所と短所を比較します。また、実際には統計的妥当性を担保する条件付き独立性テストに通らないランダム化・ハッシュ化スキームが存在することを明らかにします。
-第6節では、実務で得られた重要な教訓を共有します。

企業が実験基盤を構築すれば、テストコストや実験失敗のダメージは小さくなり、実験によるイノベーションが促進されます。「早く失敗する」ことで、アイデアの有効性を迅速に見極め、より成功し得る次のアイデアへと舵を切ることが可能になるのです。


# 2 Motivating examples

「事実が少なければ少ないほど、意見は強くなる」
― アーノルド・グラスオウ

以下の事例は、複数の領域で驚くべき結果をもたらしています。
	1.	最初の２つは、ほんの小さなUI変更が劇的な差を生んだ例です。
	2.	3番目の事例では、広告による短期的な収益向上とユーザー体験の劣化とのトレードオフを、制御実験でどのように評価・最適化したかを示します。
	3.	4番目の事例は、バックエンドアルゴリズム（この場合はAmazonの検索機能）に制御実験を適用した例です。

 ## 2.1 Checkout page at Doctor FootCare

 ECサイトのコンバージョン率とは、サイト訪問のうち購入に至った割合を指します。以下の例は Bryan Eisenberg の記事（Eisenberg 2003a, b）からのものです。

⸻

どちらのバリアントがより高いコンバージョン率を示すと思いますか？また、その差は統計的に有意だと思いますか？

図1に示す Doctor FootCare のチェックアウトページには、バリアントAとバリアントBで計9箇所の違いがあります。デザイナーがこれらを見せて「どちらを本番に出すべきか？」と尋ねられたら、あなたは正しく予測できるでしょうか？差がどれくらいあるか、またその差が有意かを見積もることができるでしょうか？

読者の皆さんにも、答えを読む前にぜひ考えてみてほしいと思います。どちらのバリアントが良いか、どの程度の差があるか、ぜひ予測してみてください。予測がいかに難しいかを実感できるはずです。

⸻

【実験結果】
バリアントAはバリアントBを10倍以上上回りました。実際にはサイト運営者がAからBに切り替えた結果、売上が90%も減少しています。ほとんどの変更点は良い方向でしたが、クーポンコード欄が致命的でした。ユーザーが「割引クーポンがあるのに自分が持っていないのでは？」と考え直してしまったためです。新バージョン（B）からクーポンコード欄を削除したところ、旧バージョン（A）と比べてコンバージョン率が6.5%向上しました。

## 2.2 Ratings of Microsoft Office help articles
Microsoft Office のヘルプを利用するユーザー（あるいは Office Online サイト（http://office.microsoft.com）を閲覧するユーザー）は、閲覧した記事を評価する機会が与えられます。初期実装では Yes/No ウィジェットが提示されていましたが、チームはこれを 5 つ星評価ウィジェットへと変更しました。

変更の動機
	1.	5 つ星評価は、より細かいフィードバックを提供し、コンテンツ制作者の評価に役立つ可能性がある。
	2.	5 つ星評価は、Yes/No 用と「理由」入力用の２つのポップアップを出す代わりに、単一のフィードバックボックスを提示することで、ユーザビリティが向上するはずである。

どちらのウィジェットの応答率※が高かったか予測できますか？
※ここで応答率とは、ウィジェットに対する何らかの操作（クリックや評価入力）を行った割合とする

驚くべきことに、5 つ星評価に切り替えたところ評価数は約 90％ 減少し、期待したユーザビリティ向上（動機 #2）を大きく逸脱しました。さらなるテストにより、２段階モデル（まず Yes/No 的な問い、次に星評価）を採用すると応答率が改善することが判明しました。具体的には、図 3 のように「Not helpful」から「Very helpful」までの 5 段階を明示した２段階モデルのウィジェットは、図 4 のシングルステージ型と比べ、応答率が 2.2 倍 に向上しました。

また、動機 #1 の「より細かいフィードバック」についても、多くのユーザーは 1 または 5 の極端な評価を選択し、中間の星をほとんど使いませんでした。助けが必要な状況では、「役に立ったか」「役に立たなかったか」の二択になりがちだったのです。

最終的にチームは、yes/no/I-don’t-know（わからない） という三択モデルを採用しました。この方式は単純な yes/no より応答率はやや下がったものの、追加の「わからない」という選択肢がもたらす情報が有用と判断されました。

## 2.3 MSN home page ads
多くのサイト運営者が直面する重要な問いは、広告をどれだけ掲載すべきかという点です。短期的には広告枠を増やすことで収益が向上しますが、特にターゲット外の広告の場合、それがユーザー体験にどのような影響を与えるかを見極めるのは難しいトレードオフです。この問いに直面したのが、2007年末のMicrosoft MSNホームページチームでした。

MSNホームページはモジュール構成になっており、ショッピングモジュールは「ファーストビュー」の右側に表示されています。提案では、このモジュールのすぐ下にさらに3件のオファーを追加するというものでした（図5）。ほとんどのユーザーにとって、それらは折り返し後の位置に表示されることになります。表示広告マーケティングチームの試算では、これらの追加オファーだけで一日数万ドルの収益が見込めるとされました。

ここでのチャレンジは、「広告収益」と「ユーザー体験の劣化」をどう比較・評価するかです。本稿第3.1節で取り上げた「OEC（Overall Evaluation Criterion：総合評価基準）」の事例です。今回は、ページビュー数とクリック数の変化を調べ、それぞれに金銭的価値を割り当てることにしました。（実験期間中、訪問頻度に統計的有意な変化は見られませんでした。）
- ページビューの価値：MSNホームページで表示される広告から得られる収益に基づく。
- クリックの価値：
1. MSNホームページから他のMSNネットワークサイト（MSN Autos、MSN Moneyなど）へ遷移したクリックに対し、その宛先サイトが評価する金銭的価値。これにより複数のページビューが生成される。
2. MSNホームページ経由ではなく検索エンジン広告（SEM）で獲得する同等のトラフィックを再獲得するために必要なクリック単価。ホームページ経由トラフィックが減少した場合、その「失われた」トラフィックをSEMで取り戻すコストです。

予想どおり、後者（#2）のSEMコストの方が高かったものの、直接収益以外の新規ユーザー獲得価値も考慮されており、両者はほぼ同等の評価額となりました。

実験はMSN USホームページのユーザーの5%を対象に12日間実施されました。その結果、クリック率は相対で0.38%減少し、統計的有意性（p=0.02）も確認されました。

この失われたクリック数を金銭的価値に換算したところ、予想される追加広告収益を上回ったため、ホームページへの広告追加案は見送られることとなりました。

## 2.4 Behavior-Based Search at Amazon
上記の事例はユーザーインターフェース（UI）の変更でしたが、ここではバックエンドのアルゴリズム変更に制御実験を適用した例をご紹介します。

2004年当時、著者の何人かが所属していた Amazon のデータマイニング＆パーソナライゼーション部門では、すでに「ある商品Xを購入した人は商品Yも購入している」という推薦アルゴリズム（購買ベース推薦）が確立されていました。これをさらに一般化し、「ある商品Xを閲覧した人は商品Yを購入している」「ある商品Xを閲覧した人は商品Yも閲覧している」というビューベース推薦も導入されていました。そこから新たに提案されたのが、「ある文字列Xで検索した人は商品Yを購入している」という行動ベース検索（Behavior-Based Search, BBS）です。UI上の表示には一切手を加えず、バックエンドの検索結果ランキングだけを変えることにより、検索結果の上位にこうした購買シグナルを反映させようというものでした。

たとえば、人が「24」というあいまいな検索語を入力したとき、従来の検索では『24 Italian Songs』のCDや24か月児向け衣料、24インチのタオルバーなど、さまざまな「24」を含む商品が返されてしまいます（この問題は検索語をユニークにする例外的な修飾語（例：「24 -foo」）を付けないかぎり、現在も同様に発生します）。一方 BBS アルゴリズムでは、「24」という検索を行った人が実際に購入したDVDボックスセットや関連書籍が上位に表示され、より適切な結果が得られます。アルゴリズムの強みは検索語の意味を理解せず、純粋に行動ログから学習する点ですが、その反面、検索語に含まれない商品が表示されることもあります。たとえば「Sony HD DVD Player」で検索すると、Sony製ではなく Toshiba製のHD DVDプレーヤーが上位に出てくることがあります。これは、SonyはBlu-rayプレーヤーを主に製造しており、多くのユーザーが「Sony HD DVD Player」で検索した後に Toshiba 製品を購入しているという行動シグナルによるものです。

こうした BBS の長所・短所を踏まえ、Amazon は制御実験を実施しました。その結果、2006年4月にワシントン大学 iEdge セミナーで公開されたところによると、この機能は Amazon の売上を約3%向上させ、数億ドル規模の増収をもたらしたと報告されています。

## 2.5 Other examples
これらは差分の大きさが極端な事例ですが、新しいデザインの成功を予測する難しさを如実に示しています。制御実験に関する emetrics 講演（Kohavi 2007）でも、さらに多くの事例が紹介されています。

優れた実験事例としては以下が挙げられます。
- Marketing Experiments 誌（McGlaughlin 2006）
- Design Choices Can Cripple a Website（Usborne 2005）
- Call to Action（Eisenberg & Eisenberg 2005）
- Which Sells Best（Eisenberg & Garcia 2006）

また、Forrester の Primer on A/B Testing（Chatham et al. 2004）には、ポジティブなROIを示す好例がいくつか載っています：
- Marriott は新しいオンライン予約フォームにより、追加で3,000万ドルの予約を獲得。
- Coach（ラグジュアリーアクセサリ小売業者）は、ベンダーに A/B テストで新検索エンジンの有効性を実証させることで、サイトの検索機能の効果を200%向上。
- Iomega（ディスクドライブメーカー）は、無料版ソフトウェアと製品版トライアルのどちらが好まれるか、どのメール用ランディングページが最良の転換率を生むかを実験的に検証し、キャンペーン成果を50%引き上げ。

さらに、Spool（2004）は Amtrak.com のサイトで登録成功率が4回に1回しかないことを指摘し、登録数が20%増えれば年間1,500万ドル以上の増収になると試算しています。
- InterContinental Hotels の A/B テストでは、検索結果に料金帯を追加して4,500万～6,000万ドルの追加予約を実現（Manning et al. 2006）。
- shop.com の The State of Retailing（Forrester Research 2005）では、米国137社の小売業者調査で「ユーザビリティテストとオファー・プロモーションの A/B テストを実施した小売業者の100%が、これらの手法を『効果的』または『非常に効果的』と評価」。
- 	Forrester の Web Analytics Spending Trends 2007（Burns 2006）では、ウェブ分析カテゴリで最も大幅な予算増加を見込んでいるのが A/B テストであり、主要予算増加を計画しているカテゴリは A/B テストと SEO/SEM の2つだけだったと報告しています。

# 3 Controlled experiments
「洗練された試行錯誤は、完璧な実行計画を立てることに勝る」
― IDEO 創業者 デイヴィッド・ケリー

「偉大なアイデアを得たければ、たくさんのアイデアを出しなさい」
― トーマス・エジソン

最も単純な制御実験（いわゆるA/Bテスト）では、ユーザーをランダムに二つのバリアントのいずれかに割り当てます：コントロール（A）またはトリートメント（B）です（図7参照；Mason et al. 1989; Box et al. 2005; Keppel et al. 1992）。

ここで重要なのは「ランダム」であることです。ユーザーを 「なんとなく」ばらまいてはいけません（Weiss 1997）。割り当てに影響を与える要因は一切許されません。収集された観測データに基づいて、各バリアントごとに総合評価基準（OEC: Overall Evaluation Criterion）を算出します（Roy 2001）。

たとえば、2.1節のチェックアウト事例では、OECとしてコンバージョン率、購入点数、収益、利益、顧客生涯価値の期待値、あるいはそれらを重み付けした指標などを用いることができます。得られたOECの差が統計的に有意かどうかを分析するわけです。

実験が適切に設計・実行されていれば、コントロールとトリートメントの差分以外に一貫した違いは存在しません。したがって、OECの差は必然的に割り当ての結果であり、因果関係が確立されます（Weiss 1997, p.215）。

ウェブ上での制御実験の基本的な解説書としては、Peterson (2004), Eisenberg & Eisenberg (2005), Chatham et al. (2004), Quarto-vonTivadar (2006), Miller (2006, 2007), Kaushik (2006), Peterson (2005), Tyler & Ledford (2006), Sterne (2002) などがあります。
<img width="670" height="470" alt="image" src="https://github.com/user-attachments/assets/8e740def-7124-4798-b95f-dfe673f064ae" />

概念自体は理解しやすく、基本的な考え方は多くの文献に通底していますが、ここで共有する重要な教訓はほとんど議論されることがありません。これらの教訓は、実験者が制御実験の適用範囲や限界を正しく理解し、結果を無効化してしまうようなミスを回避するのに役立ちます。

## 3.1 Terminology
御実験に関する用語は文献によって大きく異なります。以下では、本論文で使用する主要用語を定義し、一般に使われる代替用語を併記します。

Overall Evaluation Criterion（OEC）（Roy 2001）
実験の目的を定量化した評価尺度。統計学ではしばしば「応答変数（Response）」や「従属変数（Dependent Variable）」（Mason et al. 1989；Box et al. 2005）と呼ばれ、その他「アウトカム」「評価指標」「パフォーマンス指標」「適合度関数（Fitness Function）」（Quarto-vonTivadar 2006）などの呼称があります。複数の目的を持つ実験ではスコアカード方式を採用する場合もありますが（Kaplan & Norton 1996）、単一の指標（必要に応じて重み付きの組み合わせ）を選ぶことが強く推奨されます（Roy 2001, p.50）。単一指標により、複数実験間でのトレードオフを一度に決定でき、組織全体が明確な目的に沿って動けるようになります。なお、クリック数など短期的指標に偏らず、顧客生涯価値の予測や再訪率など長期的成果を予測する要因を含むOECが望ましいとされます（Ulwick 2005）。

Factor（要因）
OECに影響を与えると考えられる制御可能な実験変数。値（Value）を割り当て、これを「レベル（Level）」や「バージョン（Version）」とも呼びます。単純なA/Bテストでは要因は1つ、値はAとBの2つです。

Variant（バリアント）
要因のレベルを割り当てたユーザー体験のパターン。Control（既存版）またはTreatment（新バージョン）のいずれかです。「Treatment」と呼ぶ場合もありますが、本稿では既存版であるControlと、新たに試すTreatment variantsを区別して扱います。たとえばバグ発生時には実験を中止し、すべてのユーザーにControlを提示します。

Experimental unit（実験単位）
各バリアントで計測した指標を集計する対象単位。独立とみなされる「項目（item）」とも呼ばれます。ウェブ実験では多くの場合ユーザーですが、ユーザー日（user-day）、セッション、ページビューを単位とする場合もあります。いずれにせよ、ランダム割り当てはユーザー単位が望ましく、実験中一貫した体験を提供するためにユーザーIDをクッキーに保存して割り当てを行います（ユーザー単位以外のランダム化が適切な場合については付録参照）。

Null hypothesis（帰無仮説）
バリアント間でOECに差がなく、実験中に観測される違いはランダム揺らぎによるという仮説（H₀）。

Confidence level（信頼水準）
帰無仮説が真であるときに、棄却せずに維持する確率。

Power（検出力）
帰無仮説が偽であるときに、正しく棄却できる確率。差が実際に存在する場合に検出できる能力を表します。

A/A test（A/Aテスト）
「Null Test」とも呼ばれ（Peterson 2004）、A/Bテストと同じ要領でユーザーを2グループに割り当てるものの、両群に同一体験（両方ともControl）を提供します。
1. 検出力計算のためのデータ収集・ばらつき評価
2. 実験環境の検証（信頼水準95%ならば約5%の確率で帰無仮説が誤って棄却されるはず）

Standard deviation（標準偏差, Std-Dev）
ばらつきの指標。通常σで表されます。

Standard error（標準誤差, Std-Err）
サンプル統計量の標本分布の標準偏差（Mason et al. 1989）。独立観測値nの平均の標準誤差は σ̂/√n（σ̂は標本標準偏差）で計算されます。

## 3.2 Hypothesis testing and sample size

Treatment群がControl群と異なるかどうかを評価するには、統計的検定を行います。OECに差があると帰無仮説（OECに差はない）が棄却された場合、そのTreatmentは統計的に有意な差があると判断します。

検定の詳細は多くの統計書（Mason et al. 1989; Box et al. 2005; Keppel et al. 1992）に譲りますが、検定結果に影響を与える主な要因は以下のとおりです。
1. 信頼水準 (Confidence level)
通常95%に設定します。これは「差がないにもかかわらず差があると誤判断する確率」（第一種過誤）が5%であることを意味します。信頼水準を上げると、他の条件が同じでも検出力は低下します。
1. 検出力 (Power)
帰無仮説が偽（実際にOECに差がある）場合に、正しく棄却できる確率です。一般に80～95%程度が望まれますが、直接制御はできません。（帰無仮説を棄却せずに維持してしまう誤りが第二種過誤です。）
1. 標準誤差 (Standard error)
小さいほど検定の検出力が高まります。標準誤差を減らすには主に以下の3つの方法があります：

1. サンプルサイズを増やす
OECは大規模サンプルの平均であることが多く、平均の標準誤差はサンプルサイズの平方根に反比例します。したがって、実験を長く実施してサンプル数を増やせば標準誤差は減少し、検出力が向上します（Sect. 3.2.1 の例参照）。
1. ばらつきの小さいOEC成分を使う
標準偏差 σ が小さい指標を選ぶと、結果として標準誤差も小さくなります。たとえば、コンバージョン確率（0–100%）は購入単位数（小さな整数値）より標準偏差が小さく、購入単位数は収益（実数値）より小さい傾向があります（Sect. 3.2.1 の例参照）。
1. 不要なユーザーを除外してばらつきを抑える
たとえば、チェックアウトページの変更を評価する場合、そのページに到達したユーザーのみを対象に分析し、到達していないユーザーをOEC計算から除外すると、ノイズが減って標準誤差が下がります（Sect. 3.2.3 の例参照）。
